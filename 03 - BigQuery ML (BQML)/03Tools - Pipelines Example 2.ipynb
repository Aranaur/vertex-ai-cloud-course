{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b59f1fb-5557-4f89-9ee6-505e1ccc8509",
   "metadata": {},
   "source": [
    "# 03Tools - Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de3982-2555-4d5c-bae6-8e7d35710557",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Налаштування"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870ab11-b5dc-4378-830c-b39feaaa5384",
   "metadata": {},
   "source": [
    "Вхідні дані:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de005cc5-f141-4593-9f00-6d4da186424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73f2d6-e658-445c-8a2a-3c65edfe423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'pipeline_ex2'\n",
    "SERIES = '03'\n",
    "\n",
    "# data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1e984-dcde-4348-a72a-6848ac2a7538",
   "metadata": {},
   "source": [
    "пакети:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b72ce8",
   "metadata": {},
   "source": [
    "!pip install -U google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c1a4a-512f-4553-8e8c-130df1100a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import NamedTuple\n",
    "\n",
    "import kfp # used for dsl.pipeline\n",
    "import kfp.v2.dsl as dsl # used for dsl.component, dsl.Output, dsl.Input, dsl.Artifact, dsl.Model, ...\n",
    "# from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f8e48-531b-45b3-ad29-b64557cab774",
   "metadata": {},
   "source": [
    "клієнти:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2df68-d747-45e7-9448-ec9454508407",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01eff3-dd34-4842-b477-bd9d72314a8c",
   "metadata": {},
   "source": [
    "параметри:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca5abe-d716-4376-b7e7-9a8b6f8d45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}/pipelines\"\n",
    "RUN_NAME = f'run-{TIMESTAMP}'\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9f546-515b-4112-bd54-b9ab435026c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d5e930-45bc-4219-b299-1acd134b8fd5",
   "metadata": {},
   "source": [
    "Ролі сервісного акаунту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5843992-d441-4868-b3cc-09a93a8bc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba5f76-2053-4700-99db-98264bb14fc0",
   "metadata": {},
   "source": [
    ">Примітка: У списку має бути [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1d92b-35ec-4925-8aa2-e63a0dd84267",
   "metadata": {},
   "source": [
    "оточення:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e41643-6611-41dc-9519-ac0b129457d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752b9d4-1c24-4bea-ab77-4cd88d7356b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Користувацькі компоненти (KFP)\n",
    "\n",
    "Vertex AI Pipelines складаються з компонентів, які працюють незалежно, з входами і виходами, які з'єднуються у граф - конвеєр.  Для цього робочого процесу в блокноті використовуються наступні користувацькі компоненти для організації навчання моделі-кандидата, оцінки моделі-кандидата та існуючої моделі, порівняння їх на основі метрик моделі, якщо модель-кандидат краща, то замінити модель, яка вже розгорнута на існуючій кінцевій точці.  Ці кастомні компоненти побудовані як функції Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabaefb8-f1c9-41cd-8b6f-32a1e2be8715",
   "metadata": {},
   "source": [
    "### Отримайте розгорнуту модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eccaa5-a990-4a15-88aa-15a313dbfb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def get_deployed_model(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    bqml_model: dsl.Output[dsl.Artifact],\n",
    "    vertex_endpoint: dsl.Output[dsl.Artifact]\n",
    "):\n",
    "\n",
    "    # налаштування\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "\n",
    "    # отримати (або створити) кінцеву точку\n",
    "    endpoints = aiplatform.Endpoint.list(filter = f\"display_name={series} AND labels.series={series}\")\n",
    "    if endpoints:\n",
    "        endpoint = endpoints[0]\n",
    "        print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "    else:\n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "            display_name = f\"{series}\",\n",
    "            labels = {'series' : f\"{series}\"}    \n",
    "        )\n",
    "        print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "    # отримати розгорнуту модель з найбільшим трафіком і отримати ім'я BQML-моделі\n",
    "    traffic_split = endpoint.traffic_split\n",
    "    if traffic_split:\n",
    "        deployed_model_id = max(traffic_split, key = traffic_split.get)\n",
    "        if deployed_model_id:\n",
    "            for model in endpoint.list_models():\n",
    "                if model.id == deployed_model_id:\n",
    "                    deployed_model = model.model+f'@{model.model_version_id}'\n",
    "            deployed_model = aiplatform.Model(model_name = deployed_model)\n",
    "            bq_model = deployed_model.display_name+f\"_{deployed_model.labels['timestamp']}\"\n",
    "        else: bq_model = 'none'\n",
    "    else: bq_model = 'none'\n",
    "    \n",
    "    bqml_model.uri = bq_model \n",
    "    vertex_endpoint.uri = endpoint.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ebcab1-0670-4c28-9993-0d8d4bb7a78e",
   "metadata": {},
   "source": [
    "### Метрики моделі\n",
    "- Отримання прогнозів для тестових даних з моделі BigQuery\n",
    "- Обчисліть [середню точність для кривої precision-recal](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff6d61-6e04-4a2a-92f0-cd1fc508acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['pandas','db-dtypes','pyarrow','sklearn','google-cloud-bigquery']\n",
    ")\n",
    "def bqml_eval(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    var_target: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    bqml_model: dsl.Input[dsl.Model],\n",
    "    metrics: dsl.Output[dsl.Metrics],\n",
    "    metricsc: dsl.Output[dsl.ClassificationMetrics]\n",
    ") -> NamedTuple(\"model_eval\", [(\"metric\", float)]):\n",
    "\n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    from sklearn.metrics import average_precision_score, confusion_matrix\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "\n",
    "    if bqml_model.uri != 'none':\n",
    "        query = f\"\"\"\n",
    "        SELECT {var_target}, predicted_{var_target}, prob, splits \n",
    "        FROM ML.PREDICT (MODEL `{bq_project}.{bq_dataset}.{bqml_model.uri}`,(\n",
    "            SELECT *\n",
    "            FROM `{bq_project}.{bq_dataset}.{bq_table}`\n",
    "            WHERE splits = 'TEST')\n",
    "          ), UNNEST(predicted_{var_target}_probs)\n",
    "        WHERE label=1\n",
    "        \"\"\"\n",
    "        pred = bq.query(query = query).to_dataframe()\n",
    "\n",
    "        auPRC = average_precision_score(pred[var_target].astype(int), pred['prob'], average='micro')    \n",
    "        metrics.log_metric('auPRC', auPRC)\n",
    "        metricsc.log_confusion_matrix(['Not Fraud', 'Fraud'], confusion_matrix(pred[var_target].astype(int), pred[f'predicted_{var_target}'].astype(int)).tolist())\n",
    "    else:\n",
    "        auPRC = 0.0\n",
    "        metrics.log_metric('auPRC', auPRC)\n",
    "    \n",
    "    model_eval = namedtuple(\"model_eval\", [\"metric\"])\n",
    "    return model_eval(metric = float(auPRC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2dc53-92e1-477e-9a17-6418ca36ab0d",
   "metadata": {},
   "source": [
    "### BigQuery - Навчання DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd02b99-213d-454e-a372-eafaf14e56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['google-cloud-bigquery']\n",
    ")\n",
    "def bqml_dnn(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    timestamp: str,\n",
    "    var_target: str,\n",
    "    var_omit: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    bqml_model: dsl.Output[dsl.Artifact]\n",
    ") -> NamedTuple(\"bqml_training\", [(\"query\", str)]):\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "    \n",
    "    bq_model = f'{series}_{experiment}_{timestamp}'\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{bq_project}.{bq_dataset}.{bq_model}`\n",
    "    OPTIONS\n",
    "        (model_type = 'DNN_CLASSIFIER',\n",
    "            auto_class_weights = FALSE,\n",
    "            input_label_cols = ['{var_target}'],\n",
    "            data_split_col = 'custom_splits',\n",
    "            data_split_method = 'CUSTOM',\n",
    "            EARLY_STOP = FALSE,\n",
    "            OPTIMIZER = 'SGD',\n",
    "            HIDDEN_UNITS = [64, 32],\n",
    "            LEARN_RATE = 0.001,\n",
    "            ACTIVATION_FN = 'SIGMOID',\n",
    "            MAX_ITERATIONS = 15,\n",
    "            HPARAM_TUNING_ALGORITHM = 'VIZIER_DEFAULT',\n",
    "            HPARAM_TUNING_OBJECTIVES = ['ROC_AUC'],\n",
    "            DROPOUT = HPARAM_RANGE(0, 0.8),\n",
    "            BATCH_SIZE = HPARAM_RANGE(8, 500),\n",
    "            MAX_PARALLEL_TRIALS = 5,\n",
    "            NUM_TRIALS = 10\n",
    "        ) AS\n",
    "    SELECT * EXCEPT({','.join(var_omit.split())}, splits),\n",
    "        CASE\n",
    "            WHEN splits = 'VALIDATE' THEN 'EVAL'\n",
    "            ELSE splits\n",
    "        END AS custom_splits\n",
    "    FROM `{bq_project}.{bq_dataset}.{bq_table}`\n",
    "    WHERE splits != 'TEST'\n",
    "    \"\"\"\n",
    "    job = bq.query(query = query)\n",
    "    job.result()\n",
    "    bqml_model.uri = bq_model\n",
    "    \n",
    "    result = namedtuple(\"bqml_training\", [\"query\"])\n",
    "                \n",
    "    return result(query = str(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11d778-fea2-4bfd-a2d3-a896e4e4d1af",
   "metadata": {},
   "source": [
    "### Порівняння моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce2e3d-30a8-43dd-90b6-89f0c978ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component\n",
    "def model_compare(\n",
    "    base_metric: float,\n",
    "    challenger_metric: float,\n",
    ") -> bool: \n",
    "    \n",
    "    if base_metric < challenger_metric:\n",
    "        replace = True\n",
    "    else:\n",
    "        replace = False\n",
    "    \n",
    "    return replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf22f1-8e7b-4697-916a-b02c9fb127c9",
   "metadata": {},
   "source": [
    "### Експорт моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac3753-f7ee-437c-bcf6-63deed2a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['google-cloud-bigquery', 'google-cloud-aiplatform']\n",
    ")\n",
    "def bqml_export(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    timestamp: str,\n",
    "    uri: str,\n",
    "    run_name: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bqml_model: dsl.Input[dsl.Model],\n",
    "    tf_model: dsl.Output[dsl.Artifact],\n",
    "    vertex_model: dsl.Output[dsl.Artifact]\n",
    "):\n",
    "    \n",
    "    # hardcoded parameter\n",
    "    deploy_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest'\n",
    "    \n",
    "    # налаштування\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # експорт BQML Challenger Model\n",
    "    query = f\"\"\"\n",
    "    EXPORT MODEL `{bq_project}.{bq_dataset}.{bqml_model.uri}`\n",
    "        OPTIONS (URI = '{uri}/models/{timestamp}/model')\n",
    "    \"\"\"\n",
    "    export = bq.query(query = query)\n",
    "    export.result()\n",
    "    \n",
    "    # завантаження морделі до Vertex AI Model Registry\n",
    "    modelmatch = aiplatform.Model.list(filter = f'display_name={series}_{experiment} AND labels.series={series} AND labels.experiment={experiment}')\n",
    "\n",
    "    upload_model = True\n",
    "    if modelmatch:\n",
    "        print(\"Model Already in Registry:\")\n",
    "        if run_name in modelmatch[0].version_aliases:\n",
    "            print(\"This version already loaded, no action taken.\")\n",
    "            upload_model = False\n",
    "            model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "        else:\n",
    "            print('Loading model as new default version.')\n",
    "            parent_model =  modelmatch[0].resource_name\n",
    "    else:\n",
    "        print('This is a new model, adding to model registry as version 1')\n",
    "        parent_model = ''\n",
    "\n",
    "    if upload_model:\n",
    "        model = aiplatform.Model.upload(\n",
    "            display_name = f'{series}_{experiment}',\n",
    "            model_id = f'model_{series}_{experiment}',\n",
    "            parent_model = parent_model,\n",
    "            serving_container_image_uri = deploy_image,\n",
    "            artifact_uri = f\"{uri}/models/{timestamp}/model\",\n",
    "            is_default_version = True,\n",
    "            version_aliases = [run_name],\n",
    "            version_description = run_name,\n",
    "            labels = {'series' : f'{series}', 'experiment' : f'{experiment}', 'timestamp': f'{timestamp}', 'run_name' : f'{run_name}'}\n",
    "        )  \n",
    "    \n",
    "    tf_model.uri = f'{uri}/models/{timestamp}/model'\n",
    "    vertex_model.uri = model.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdb4a1-a1b7-4403-bc44-bce46b981c91",
   "metadata": {},
   "source": [
    "### Заміна моделі в кінцевій точці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433281e-390d-4ab5-bcfa-c171a72f7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def endpoint_update(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    vertex_endpoint: dsl.Input[dsl.Artifact],\n",
    "    vertex_model: dsl.Input[dsl.Model]\n",
    "):\n",
    "    \n",
    "    # hardcoded parameter\n",
    "    deploy_compute = 'n1-standard-4'\n",
    "    \n",
    "    # налаштування\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "\n",
    "    # отримання кінцевої точки\n",
    "    endpoint = aiplatform.Endpoint(vertex_endpoint.uri)\n",
    "    \n",
    "    # отримання моделі\n",
    "    model = aiplatform.Model(vertex_model.uri)\n",
    "    \n",
    "    # розгорнути модель на кінцевій точці зі 100% трафіку\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = deploy_compute,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "    \n",
    "    # видалити моделей з 0 трафіку\n",
    "    for deployed_model in endpoint.list_models():\n",
    "        if deployed_model.id in endpoint.traffic_split:\n",
    "            print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "        else:\n",
    "            endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "            print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9535c2f-0f05-4c15-89de-c6cf135f7dd3",
   "metadata": {},
   "source": [
    "---\n",
    "## Ініціалізація Pipeline (KFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0342ef-5792-4060-afbd-01ca1cf9ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name = f'series-{SERIES}-endpoint-challenger',\n",
    "    description = 'Update endpoint with challenger model (conditionally).'\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    timestamp: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    var_target: str,\n",
    "    var_omit: str,\n",
    "    uri: str,\n",
    "    run_name: str\n",
    "):\n",
    "   \n",
    "    # get the current model\n",
    "    current_model = get_deployed_model(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series\n",
    "    ).set_display_name('Get Current Model').set_caching_options(False)\n",
    "\n",
    "    # get AUC for current model\n",
    "    base_model_eval = bqml_eval(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        var_target = var_target,\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table,\n",
    "        bqml_model = current_model.outputs['bqml_model']\n",
    "    ).set_display_name('Metric for Current Model').set_caching_options(False)\n",
    "    \n",
    "    # train challenger model with BQML\n",
    "    challenger_model = bqml_dnn(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series,\n",
    "        experiment = experiment,\n",
    "        timestamp = timestamp,\n",
    "        var_target = var_target,\n",
    "        var_omit = var_omit,\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table\n",
    "    ).set_display_name('Train Challenger Model').set_caching_options(True)\n",
    "    \n",
    "    # get AUC for challenger model\n",
    "    challenger_model_eval = bqml_eval(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        var_target = var_target,\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table,\n",
    "        bqml_model = challenger_model.outputs['bqml_model']\n",
    "    ).set_display_name('Metric for Challenger Model').set_caching_options(False)\n",
    "    challenger_model_eval.after(challenger_model)\n",
    "    \n",
    "    # compare models\n",
    "    compare = model_compare(\n",
    "        base_metric = base_model_eval.outputs[\"metric\"],\n",
    "        challenger_metric = challenger_model_eval.outputs[\"metric\"]\n",
    "    ).set_display_name('Compare Models')\n",
    "    \n",
    "    # conditional deployment\n",
    "    with dsl.Condition(\n",
    "        compare.output == 'true',\n",
    "        name = \"replace_model\"\n",
    "    ):\n",
    "        # export BQML model to Vertex AI Model Registry\n",
    "        export = bqml_export(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series,\n",
    "            experiment = experiment,\n",
    "            timestamp = timestamp,\n",
    "            uri = uri,\n",
    "            run_name = run_name,\n",
    "            bq_project = bq_project,\n",
    "            bq_dataset = bq_dataset,\n",
    "            bqml_model = challenger_model.outputs[\"bqml_model\"]\n",
    "        ).set_display_name('Export BQML Model')\n",
    "        \n",
    "        # replace model on endpoint (03b)\n",
    "        replace = endpoint_update(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series,\n",
    "            experiment = experiment,\n",
    "            vertex_endpoint = current_model.outputs['vertex_endpoint'],\n",
    "            vertex_model = export.outputs['vertex_model']\n",
    "        ).set_display_name('Deploy The Challenger Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfa7eb-910f-47b8-b1d2-a2ab0ce552ce",
   "metadata": {},
   "source": [
    "---\n",
    "## Компіляція та запуск конвеєра"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf95030-c36c-460f-9cfe-ede7aa7b5621",
   "metadata": {},
   "source": [
    "### Компіляція вхідних даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32c99d-841a-49c2-a9db-a413b41c08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values = {\n",
    "    \"project\" : PROJECT_ID,\n",
    "    \"region\" : REGION,\n",
    "    \"series\": SERIES,\n",
    "    \"experiment\" : EXPERIMENT,\n",
    "    \"timestamp\": TIMESTAMP,\n",
    "    \"bq_project\": BQ_PROJECT,\n",
    "    \"bq_dataset\": BQ_DATASET,\n",
    "    \"bq_table\": BQ_TABLE,\n",
    "    \"var_target\": VAR_TARGET,\n",
    "    \"var_omit\": VAR_OMIT,\n",
    "    \"uri\": URI,\n",
    "    \"run_name\": RUN_NAME\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936b132-adb8-4dcd-b8a1-ec68c1743a3a",
   "metadata": {},
   "source": [
    "### Компіляція конвеєра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47369f8c-8a42-4e7d-8920-3d9e038a10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2 import compiler\n",
    "kfp.v2.compiler.Compiler().compile(\n",
    "    pipeline_func = pipeline,\n",
    "    package_path = f\"{DIR}/{EXPERIMENT}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d0797-3f30-41b4-82af-a82c33f26133",
   "metadata": {},
   "source": [
    "### Визначення завдання конвеєра\n",
    "\n",
    "Використання скомпільованого конвеєра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38dd6b9-9297-402d-9856-cf3731ccaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = f'{EXPERIMENT}',\n",
    "    template_path = f\"{DIR}/{EXPERIMENT}.json\",\n",
    "    pipeline_root = f\"{URI}/pipeline_root\",\n",
    "    parameter_values = parameter_values,\n",
    "    enable_caching = False, # overrides all component/task settings\n",
    "    labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1429e4d-9293-48f8-997a-eb85d562b56c",
   "metadata": {},
   "source": [
    "### Подання Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4118c-616f-4285-bb1d-928f954ad9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2320f1-bcd4-4c23-a739-e9c932625cdd",
   "metadata": {},
   "source": [
    "Перейдіть за наступним посиланням, щоб переглянути завдання в консолі GCP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17567cb-1038-46ca-8f52-e90cf2291f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Інформаційну панель можна переглянути тут:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537079d-839a-4cba-bdf7-b6df8b81627d",
   "metadata": {},
   "source": [
    "#### Очікування завершення конвеєра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7251a9-d2b6-4fa3-a442-b9f644b8675e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099c0cf-2304-46cb-b993-2311f75ad241",
   "metadata": {},
   "source": [
    "### Отримання інформації про конвеєр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c0d7f-8bdd-4380-828b-cae9dc4c0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'series-{SERIES}-endpoint-challenger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e69dc-2724-400a-8bb1-b4c349441dde",
   "metadata": {},
   "source": [
    "## Огляд конвеєра\n",
    "\n",
    "<p aligh=\"center\"><center><img src=\"../architectures/notebooks/03/pipeline_ex2.png\" width=\"75%\"></center></p>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
