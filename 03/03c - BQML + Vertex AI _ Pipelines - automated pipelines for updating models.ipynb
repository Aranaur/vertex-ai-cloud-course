{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b59f1fb-5557-4f89-9ee6-505e1ccc8509",
   "metadata": {},
   "source": [
    "# 03c - BQML + Vertex AI > Pipelines - automated pipelines for updating models\n",
    "\n",
    "As time goes on change occurs:\n",
    "- inputs to our models may shift in distribution compared to when the model was trained - called training-serving skew\n",
    "- inputs to out models may shift over time - called prediction drift\n",
    "- new inputs/features may become available\n",
    "- a better model may be created\n",
    "\n",
    "In the `03b` notebook we deployed the model built with BQML in the `03a` notebook to a Vertex AI Endpoint for online prediction.  In this notebook we will build a challenger model with the same training data, also using BQML but with a different model type - a deep neural network similar what we build in the `05` series of ntoebooks.  We will construct a Vertex AI Pipeline to orchestrate the process of building the new model, comparing to the deployed mode, and conditionally replacing the deployed model with the new one.  \n",
    "\n",
    "This process could be triggered based on time elapsed, amount of new data, detected training-serving skew or even prediction drift by using Vertex AI Monitoring.  \n",
    "\n",
    "### Video Walkthrough of this notebook:\n",
    "Includes conversational walkthrough and more explanatory information than the notebook:\n",
    "\n",
    "<p><center><a href=\"https://youtu.be/kzDd94KucBQ\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"architectures/thumbnails/playbutton/03c.png\" width=\"50%\"></a></center></p>\n",
    "\n",
    "### Prerequisites:\n",
    "-  03a - BigQuery Machine Learning (BQML) - Machine Learning with SQL\n",
    "-  03b - Vertex AI + BQML - Online Predictions with BQML Models\n",
    "\n",
    "### Overview:\n",
    "- Build Custom Pipeline Components\n",
    "    - Use BigQuery ML to Get Predictions and Scikit-Learn to calculate model metrics\n",
    "    - Use BigQuery ML to train a new model - A Deep Neural Network\n",
    "    - Compare model metrics for baseline and challenger model\n",
    "    - Export BigQuery ML model to Google Cloud Storage\n",
    "    - Replace a model deployed to an endpoint (`03b`) with the challenger model, undeploy previous model\n",
    "- Define the Pipeline Flow\n",
    "- Compile the Pipeline\n",
    "- Run the Pipeline in Vertex AI\n",
    "- Get Predictions from the upated Endpoint\n",
    "\n",
    "### Resources:\n",
    "-  [Export formats for BigQuery ML models](https://cloud.google.com/bigquery-ml/docs/exporting-models)\n",
    "-  [Python Client for Vertex AI](https://googleapis.dev/python/aiplatform/latest/aiplatform.html)\n",
    "-  Codelab: [Vertex AI Pipelines Introduction](https://codelabs.developers.google.com/vertex-mlmd-pipelines#0)\n",
    "-  [Vertex AI Prebuilt KFP Components](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5855d-e3ff-464c-af1d-d7f0aa52cd1c",
   "metadata": {},
   "source": [
    "---\n",
    "## Vertex AI - Conceptual Flow\n",
    "\n",
    "<img src=\"architectures/slides/03c_arch.png\">\n",
    "\n",
    "---\n",
    "## Vertex AI - Workflow\n",
    "\n",
    "<img src=\"architectures/slides/03c_console.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de3982-2555-4d5c-bae6-8e7d35710557",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870ab11-b5dc-4378-830c-b39feaaa5384",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de005cc5-f141-4593-9f00-6d4da186424f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb73f2d6-e658-445c-8a2a-3c65edfe423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "DATANAME = 'fraud'\n",
    "NOTEBOOK = '03c'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_IMAGE='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1e984-dcde-4348-a72a-6848ac2a7538",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968c1a4a-512f-4553-8e8c-130df1100a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "from typing import NamedTuple\n",
    "import kfp # used for dsl.pipeline\n",
    "import kfp.v2.dsl as dsl # used for dsl.component, dsl.Output, dsl.Input, dsl.Artifact, dsl.Model, ...\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f8e48-531b-45b3-ad29-b64557cab774",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd2df68-d747-45e7-9448-ec9454508407",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01eff3-dd34-4842-b477-bd9d72314a8c",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ca5abe-d716-4376-b7e7-9a8b6f8d45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{DATANAME}/models/{NOTEBOOK}\"\n",
    "DIR = f\"temp/{NOTEBOOK}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b750a1d-5080-4136-a9de-0d345147a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give service account roles/storage.objectAdmin permissions\n",
    "# Console > IMA > Select Account <projectnumber>-compute@developer.gserviceaccount.com > edit - give role\n",
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1d92b-35ec-4925-8aa2-e63a0dd84267",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e41643-6611-41dc-9519-ac0b129457d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752b9d4-1c24-4bea-ab77-4cd88d7356b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Custom Components (KFP)\n",
    "\n",
    "Vertex AI Pipelines are made up of components that run independently with inputs and outputs that connect to form a graph - the pipeline.  For this notebook workflow the following custom components are used to orchestrate the training of a challenger model, evaluating the challenger and an existing model, comparing them based on model metrics, if the challenger is better then replace the model already deployed on an existing endpoint.  These custom components are constructed as python functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ebcab1-0670-4c28-9993-0d8d4bb7a78e",
   "metadata": {},
   "source": [
    "### Model Metrics\n",
    "- Get Predictions for Test data from BigQuery Model\n",
    "- Calculate [average precision for the precision-recall curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8ff6d61-6e04-4a2a-92f0-cd1fc508acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['pandas','db-dtypes','pyarrow','sklearn','google-cloud-bigquery']\n",
    ")\n",
    "def bqml_eval(\n",
    "    project: str,\n",
    "    var_target: str,\n",
    "    model: str,\n",
    "    dataname: str,\n",
    "    metrics: dsl.Output[dsl.Metrics],\n",
    "    metricsc: dsl.Output[dsl.ClassificationMetrics]\n",
    ") -> NamedTuple(\"model_eval\", [(\"metric\", float)]):\n",
    "\n",
    "    from collections import namedtuple\n",
    "    from sklearn.metrics import average_precision_score, confusion_matrix\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT {var_target}, predicted_{var_target}, prob, splits \n",
    "    FROM ML.PREDICT (MODEL `{project}.{dataname}.{model}`,(\n",
    "        SELECT *\n",
    "        FROM `{project}.{dataname}.{dataname}_prepped`\n",
    "        WHERE splits = 'TEST')\n",
    "      ), UNNEST(predicted_{var_target}_probs)\n",
    "    WHERE label=1\n",
    "    \"\"\"\n",
    "    pred = bq.query(query = query).to_dataframe()\n",
    "\n",
    "    auPRC = average_precision_score(pred[var_target].astype(int), pred['prob'], average='micro')    \n",
    "    metrics.log_metric('auPRC', auPRC)\n",
    "    metricsc.log_confusion_matrix(['Not Fraud', 'Fraud'], confusion_matrix(pred[var_target].astype(int), pred[f'predicted_{var_target}'].astype(int)).tolist())\n",
    "    \n",
    "    model_eval = namedtuple(\"model_eval\", [\"metric\"])\n",
    "    return model_eval(metric = float(auPRC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2dc53-92e1-477e-9a17-6418ca36ab0d",
   "metadata": {},
   "source": [
    "### BigQuery - Train DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bd02b99-213d-454e-a372-eafaf14e56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['google-cloud-bigquery']\n",
    ")\n",
    "def bqml_dnn(\n",
    "    project: str,\n",
    "    var_target: str,\n",
    "    var_omit: str,\n",
    "    model: str,\n",
    "    dataname: str,\n",
    "    bqml_model: dsl.Output[dsl.Artifact]\n",
    ") -> NamedTuple(\"bqml_training\", [(\"query\", str)]):\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{project}.{dataname}.{model}`\n",
    "    OPTIONS\n",
    "        (model_type = 'DNN_CLASSIFIER',\n",
    "            auto_class_weights = FALSE,\n",
    "            input_label_cols = ['{var_target}'],\n",
    "            data_split_col = 'custom_splits',\n",
    "            data_split_method = 'CUSTOM',\n",
    "            EARLY_STOP = FALSE,\n",
    "            OPTIMIZER = 'SGD',\n",
    "            HIDDEN_UNITS = [2],\n",
    "            LEARN_RATE = 0.001,\n",
    "            ACTIVATION_FN = 'SIGMOID',\n",
    "            MAX_ITERATIONS = 10,\n",
    "            HPARAM_TUNING_ALGORITHM = 'VIZIER_DEFAULT',\n",
    "            HPARAM_TUNING_OBJECTIVES = ['ROC_AUC'],\n",
    "            DROPOUT = HPARAM_RANGE(0, 0.8),\n",
    "            BATCH_SIZE = HPARAM_RANGE(8, 500),\n",
    "            MAX_PARALLEL_TRIALS = 2,\n",
    "            NUM_TRIALS = 20\n",
    "        ) AS\n",
    "    SELECT * EXCEPT({','.join(var_omit.split())}, splits),\n",
    "        CASE\n",
    "            WHEN splits = 'VALIDATE' THEN 'EVAL'\n",
    "            ELSE splits\n",
    "        END AS custom_splits\n",
    "    FROM `{project}.{dataname}.{dataname}_prepped`\n",
    "    WHERE splits != 'TEST'\n",
    "    \"\"\"\n",
    "    job = bq.query(query = query)\n",
    "    job.result()\n",
    "    bqml_model.uri = f\"bq://{project}.{dataname}.{model}\"\n",
    "    \n",
    "    result = namedtuple(\"bqml_training\", [\"query\"])\n",
    "                \n",
    "    return result(query = str(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11d778-fea2-4bfd-a2d3-a896e4e4d1af",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6ce2e3d-30a8-43dd-90b6-89f0c978ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component\n",
    "def model_compare(\n",
    "    base_metric: float,\n",
    "    challenger_metric: float,\n",
    ") -> bool: \n",
    "    \n",
    "    if base_metric < challenger_metric:\n",
    "        replace = True\n",
    "    else:\n",
    "        replace = False\n",
    "    \n",
    "    return replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf22f1-8e7b-4697-916a-b02c9fb127c9",
   "metadata": {},
   "source": [
    "### Export BQML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3ac3753-f7ee-437c-bcf6-63deed2a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['google-cloud-bigquery']\n",
    ")\n",
    "def bqml_export(\n",
    "    project: str,\n",
    "    export_location: str,\n",
    "    bqml_model: dsl.Input[dsl.Model],\n",
    "    tf_model: dsl.Output[dsl.Artifact],  \n",
    "):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "    \n",
    "    bqml_model_name = bqml_model.uri.split(\"/\")[-1]\n",
    "    export = bq.query(query = f\"EXPORT MODEL `{bqml_model_name}` OPTIONS(URI = '{export_location}')\")\n",
    "    export.result()\n",
    "    \n",
    "    tf_model.uri = export_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdb4a1-a1b7-4403-bc44-bce46b981c91",
   "metadata": {},
   "source": [
    "### Replace Model On Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2433281e-390d-4ab5-bcfa-c171a72f7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    packages_to_install = ['google-cloud-aiplatform'],\n",
    "    base_image = 'python:3.9'\n",
    ")\n",
    "def endpoint_update(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    endpoint_prefix: str,\n",
    "    newmodel: dsl.Input[dsl.Model],\n",
    "    display_name: str,\n",
    "    deploy_machine: str,\n",
    "    deploy_container: str,\n",
    "    label: str\n",
    "):\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "\n",
    "    # upload new model (03c)\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = display_name,\n",
    "        serving_container_image_uri = deploy_container,\n",
    "        artifact_uri = newmodel.uri,\n",
    "        labels = {'notebook':f'{label}'}\n",
    "    )\n",
    "    \n",
    "    # find endpoint from notebook 03b\n",
    "    for e in aiplatform.Endpoint.list():\n",
    "        if e.display_name.startswith(endpoint_prefix): endpoint = e\n",
    "    print(endpoint.display_name)\n",
    "\n",
    "    # list model(s) on 03b endpoint\n",
    "    models = endpoint.list_models()\n",
    "    if len(models) == 1:\n",
    "        oldmodel = models[0]\n",
    "    print(oldmodel)\n",
    "    \n",
    "    # deploy 03c model to endpoint with traffic_split = 100\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = deploy_machine,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "    \n",
    "    # undeploy 03b model\n",
    "    endpoint.undeploy(\n",
    "        deployed_model_id = oldmodel.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9535c2f-0f05-4c15-89de-c6cf135f7dd3",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline (KFP) Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d0342ef-5792-4060-afbd-01ca1cf9ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name = f'kfp-{NOTEBOOK}-{DATANAME}-{TIMESTAMP}', \n",
    "    pipeline_root = URI+'/'+str(TIMESTAMP)+'/kfp/'\n",
    ")\n",
    "def pipeline(\n",
    "    endpoint_prefix: str,\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION,\n",
    "    dataname: str = DATANAME,\n",
    "    display_name: str = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    deploy_machine: str = DEPLOY_COMPUTE,\n",
    "    deploy_container: str = DEPLOY_IMAGE,\n",
    "    bq_source: str = f'bq://{PROJECT_ID}.{DATANAME}.{DATANAME}_prepped',\n",
    "    var_target: str = VAR_TARGET,\n",
    "    var_omit: str = VAR_OMIT,\n",
    "    uri: str = URI,\n",
    "    label: str = NOTEBOOK \n",
    "):\n",
    "        \n",
    "    # get AUC for current model\n",
    "    base_model_eval = bqml_eval(\n",
    "        project = project,\n",
    "        var_target = var_target,\n",
    "        model = f'{dataname}_lr',\n",
    "        dataname = dataname\n",
    "    )\n",
    "    base_model_eval.set_caching_options(False)\n",
    "    \n",
    "    # train challenger model with BQML\n",
    "    challenger_model = bqml_dnn(\n",
    "        project = project,\n",
    "        var_target = var_target,\n",
    "        var_omit = var_omit,\n",
    "        model = f'{dataname}_dnn',\n",
    "        dataname = dataname,\n",
    "    )\n",
    "    challenger_model.set_caching_options(True)\n",
    "    \n",
    "    # get AUC for challenger model\n",
    "    challenger_model_eval = bqml_eval(\n",
    "        project = project,\n",
    "        var_target = var_target,\n",
    "        model = f'{dataname}_dnn',\n",
    "        dataname = dataname\n",
    "    )\n",
    "    challenger_model_eval.set_caching_options(False)\n",
    "    challenger_model_eval.after(challenger_model)\n",
    "    \n",
    "    # compare models\n",
    "    compare = model_compare(\n",
    "        base_metric = base_model_eval.outputs[\"metric\"],\n",
    "        challenger_metric = challenger_model_eval.outputs[\"metric\"]\n",
    "    )\n",
    "    \n",
    "    # conditional deployment\n",
    "    with dsl.Condition(\n",
    "        compare.output == 'true',\n",
    "        name = \"replace_model\"\n",
    "    ):\n",
    "        # export BQML model\n",
    "        export = bqml_export(\n",
    "            project = project,\n",
    "            export_location = uri,\n",
    "            bqml_model = challenger_model.outputs[\"bqml_model\"]\n",
    "        )\n",
    "        \n",
    "        # replace model on endpoint (03b)\n",
    "        replace = endpoint_update(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            endpoint_prefix = endpoint_prefix,\n",
    "            newmodel = export.outputs[\"tf_model\"],\n",
    "            display_name = display_name,\n",
    "            deploy_machine = deploy_machine,\n",
    "            deploy_container = deploy_container,\n",
    "            label = label\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfa7eb-910f-47b8-b1d2-a2ab0ce552ce",
   "metadata": {},
   "source": [
    "---\n",
    "## Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf89c7db-130a-4bbf-a358-ca99b2bd4e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "    pipeline_func = pipeline,\n",
    "    package_path = f\"{DIR}/{NOTEBOOK}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1e6b7-b504-4317-95f8-bca787948dcb",
   "metadata": {},
   "source": [
    "Move compiled pipeline files to GCS Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d316e8f9-3eb1-46df-81bc-a3cf6d458922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://temp/03c/03c.json [Content-Type=application/json]...\n",
      "/ [1 files][ 31.1 KiB/ 31.1 KiB]                                                \n",
      "Operation completed over 1 objects/31.1 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {DIR}/{NOTEBOOK}.json {URI}/{TIMESTAMP}/kfp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d0797-3f30-41b4-82af-a82c33f26133",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Vertex AI Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e38dd6b9-9297-402d-9856-cf3731ccaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name = f'{NOTEBOOK}_{DATANAME}_{TIMESTAMP}',\n",
    "    template_path = f\"{URI}/{TIMESTAMP}/kfp/{NOTEBOOK}.json\",\n",
    "    pipeline_root = f\"{URI}/{TIMESTAMP}/kfp/\",\n",
    "    parameter_values = {\"endpoint_prefix\": \"03b\"},\n",
    "    enable_caching = None,\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51c4118c-616f-4285-bb1d-928f954ad9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/kfp-03c-fraud-20220707160930-20220707162146?project=1026793852137\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/kfp-03c-fraud-20220707160930-20220707162146\n"
     ]
    }
   ],
   "source": [
    "response = pipeline.run(service_account = SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "002c0d7f-8bdd-4380-828b-cae9dc4c0b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:var_omit</th>\n",
       "      <th>param.input:bq_source</th>\n",
       "      <th>param.input:label</th>\n",
       "      <th>param.input:display_name</th>\n",
       "      <th>param.input:region</th>\n",
       "      <th>param.input:dataname</th>\n",
       "      <th>param.input:deploy_container</th>\n",
       "      <th>param.input:project</th>\n",
       "      <th>param.input:uri</th>\n",
       "      <th>param.input:endpoint_prefix</th>\n",
       "      <th>param.input:deploy_machine</th>\n",
       "      <th>param.input:var_target</th>\n",
       "      <th>metric.confusionMatrix</th>\n",
       "      <th>metric.auPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kfp-03c-fraud-20220707160930</td>\n",
       "      <td>kfp-03c-fraud-20220707160930-20220707162146</td>\n",
       "      <td>transaction_id</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>03c</td>\n",
       "      <td>03c_fraud_20220707160930</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>fraud</td>\n",
       "      <td>us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>gs://statmike-mlops-349915/fraud/models/03c</td>\n",
       "      <td>03b</td>\n",
       "      <td>n1-standard-4</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'annotationSpecs': [{'displayName': 'Not Frau...</td>\n",
       "      <td>0.806335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kfp-03c-fraud-20220707160930</td>\n",
       "      <td>kfp-03c-fraud-20220707160930-20220707161243</td>\n",
       "      <td>transaction_id</td>\n",
       "      <td>bq://statmike-mlops-349915.fraud.fraud_prepped</td>\n",
       "      <td>03c</td>\n",
       "      <td>03c_fraud_20220707160930</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>fraud</td>\n",
       "      <td>us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu...</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>gs://statmike-mlops-349915/fraud/models/03c</td>\n",
       "      <td>03b</td>\n",
       "      <td>n1-standard-4</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pipeline_name                                     run_name  \\\n",
       "0  kfp-03c-fraud-20220707160930  kfp-03c-fraud-20220707160930-20220707162146   \n",
       "1  kfp-03c-fraud-20220707160930  kfp-03c-fraud-20220707160930-20220707161243   \n",
       "\n",
       "  param.input:var_omit                           param.input:bq_source  \\\n",
       "0       transaction_id  bq://statmike-mlops-349915.fraud.fraud_prepped   \n",
       "1       transaction_id  bq://statmike-mlops-349915.fraud.fraud_prepped   \n",
       "\n",
       "  param.input:label  param.input:display_name param.input:region  \\\n",
       "0               03c  03c_fraud_20220707160930        us-central1   \n",
       "1               03c  03c_fraud_20220707160930        us-central1   \n",
       "\n",
       "  param.input:dataname                       param.input:deploy_container  \\\n",
       "0                fraud  us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu...   \n",
       "1                fraud  us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu...   \n",
       "\n",
       "     param.input:project                              param.input:uri  \\\n",
       "0  statmike-mlops-349915  gs://statmike-mlops-349915/fraud/models/03c   \n",
       "1  statmike-mlops-349915  gs://statmike-mlops-349915/fraud/models/03c   \n",
       "\n",
       "  param.input:endpoint_prefix param.input:deploy_machine  \\\n",
       "0                         03b              n1-standard-4   \n",
       "1                         03b              n1-standard-4   \n",
       "\n",
       "  param.input:var_target                             metric.confusionMatrix  \\\n",
       "0                  Class  {'annotationSpecs': [{'displayName': 'Not Frau...   \n",
       "1                  Class                                                NaN   \n",
       "\n",
       "   metric.auPRC  \n",
       "0      0.806335  \n",
       "1           NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'kfp-{NOTEBOOK}-{DATANAME}-{TIMESTAMP}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e69dc-2724-400a-8bb1-b4c349441dde",
   "metadata": {},
   "source": [
    "## Review Pipeline Run\n",
    "\n",
    "<img src=\"architectures/notebooks/03c_screenshots/kfp_pipeline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11a7b6-4f0d-41b7-8225-5ffbb2327368",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e0959-98a1-459f-8a5d-4f601e217b6f",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bda8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = bq.query(query = f\"SELECT * FROM {DATANAME}.{DATANAME}_prepped WHERE splits='TEST' LIMIT 10\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb5a77b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32799</td>\n",
       "      <td>1.153477</td>\n",
       "      <td>-0.047859</td>\n",
       "      <td>1.358363</td>\n",
       "      <td>1.480620</td>\n",
       "      <td>-1.222598</td>\n",
       "      <td>-0.481690</td>\n",
       "      <td>-0.654461</td>\n",
       "      <td>0.128115</td>\n",
       "      <td>0.907095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025964</td>\n",
       "      <td>0.701843</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>-0.257691</td>\n",
       "      <td>0.060115</td>\n",
       "      <td>0.035332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>e9d16028-4b41-4753-87ee-041d33642ae9</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35483</td>\n",
       "      <td>1.286640</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.212182</td>\n",
       "      <td>-0.269732</td>\n",
       "      <td>-0.283961</td>\n",
       "      <td>-0.663306</td>\n",
       "      <td>-0.016385</td>\n",
       "      <td>-0.120297</td>\n",
       "      <td>-0.135962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052674</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.209208</td>\n",
       "      <td>0.847617</td>\n",
       "      <td>-0.086559</td>\n",
       "      <td>-0.008262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8b319d3a-2b2d-445b-a9a2-0da3d664ec2a</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163935</td>\n",
       "      <td>1.961967</td>\n",
       "      <td>-0.247295</td>\n",
       "      <td>-1.751841</td>\n",
       "      <td>-0.268689</td>\n",
       "      <td>0.956431</td>\n",
       "      <td>0.707211</td>\n",
       "      <td>0.020675</td>\n",
       "      <td>0.189433</td>\n",
       "      <td>0.455055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186420</td>\n",
       "      <td>-1.621368</td>\n",
       "      <td>-0.131098</td>\n",
       "      <td>0.034276</td>\n",
       "      <td>-0.004909</td>\n",
       "      <td>-0.090859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>788afb87-60aa-4482-8b48-c924bec634aa</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30707</td>\n",
       "      <td>-0.964364</td>\n",
       "      <td>0.176372</td>\n",
       "      <td>2.464128</td>\n",
       "      <td>2.672539</td>\n",
       "      <td>0.145676</td>\n",
       "      <td>-0.152913</td>\n",
       "      <td>-0.591983</td>\n",
       "      <td>0.305066</td>\n",
       "      <td>-0.148034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024200</td>\n",
       "      <td>0.365226</td>\n",
       "      <td>-0.745369</td>\n",
       "      <td>-0.060544</td>\n",
       "      <td>0.095692</td>\n",
       "      <td>0.217639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>473d0936-1974-4ae8-ab70-230e7599bd3f</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   32799  1.153477 -0.047859  1.358363  1.480620 -1.222598 -0.481690   \n",
       "1   35483  1.286640  0.072917  0.212182 -0.269732 -0.283961 -0.663306   \n",
       "2  163935  1.961967 -0.247295 -1.751841 -0.268689  0.956431  0.707211   \n",
       "3   30707 -0.964364  0.176372  2.464128  2.672539  0.145676 -0.152913   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0 -0.654461  0.128115  0.907095  ... -0.025964  0.701843  0.417245 -0.257691   \n",
       "1 -0.016385 -0.120297 -0.135962  ...  0.052674  0.076792  0.209208  0.847617   \n",
       "2  0.020675  0.189433  0.455055  ...  0.186420 -1.621368 -0.131098  0.034276   \n",
       "3 -0.591983  0.305066 -0.148034  ... -0.024200  0.365226 -0.745369 -0.060544   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0  0.060115  0.035332     0.0      0  e9d16028-4b41-4753-87ee-041d33642ae9   \n",
       "1 -0.086559 -0.008262     0.0      0  8b319d3a-2b2d-445b-a9a2-0da3d664ec2a   \n",
       "2 -0.004909 -0.090859     0.0      0  788afb87-60aa-4482-8b48-c924bec634aa   \n",
       "3  0.095692  0.217639     0.0      0  473d0936-1974-4ae8-ab70-230e7599bd3f   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c32ed6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': 32799,\n",
       " 'V1': 1.15347743766561,\n",
       " 'V2': -0.0478588055804616,\n",
       " 'V3': 1.35836288729212,\n",
       " 'V4': 1.48062009487976,\n",
       " 'V5': -1.22259808550513,\n",
       " 'V6': -0.481689608379461,\n",
       " 'V7': -0.6544612667240159,\n",
       " 'V8': 0.128114599402494,\n",
       " 'V9': 0.907094671648477,\n",
       " 'V10': -0.0364175882073298,\n",
       " 'V11': -0.659895142180526,\n",
       " 'V12': -0.307334930019039,\n",
       " 'V13': -1.3656343720183501,\n",
       " 'V14': 0.035305634441467997,\n",
       " 'V15': 0.7114399756440071,\n",
       " 'V16': 0.25384340384905,\n",
       " 'V17': -0.22283165732475999,\n",
       " 'V18': 0.26559908021792394,\n",
       " 'V19': -0.5970199308963089,\n",
       " 'V20': -0.24568562944008399,\n",
       " 'V21': 0.12551444308840598,\n",
       " 'V22': 0.480049308608633,\n",
       " 'V23': -0.0259637518455547,\n",
       " 'V24': 0.7018428515999721,\n",
       " 'V25': 0.41724451503333504,\n",
       " 'V26': -0.257690694038964,\n",
       " 'V27': 0.06011458360133701,\n",
       " 'V28': 0.0353320583585812,\n",
       " 'Amount': 0.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newob = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')[0]\n",
    "newob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01139225-025d-444f-9bf8-2af525730732",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client\n",
    "This model does not have the default signature name expected by Vertex AI endpoint of \"serving_default\".  To get arround this we prepare the json input to include the correct signature name and use the [raw_predict method with the PredictionService documented here](https://googleapis.dev/python/aiplatform/latest/aiplatform_v1/prediction_service.html#google.cloud.aiplatform_v1.services.prediction_service.PredictionServiceClient.raw_predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "279cf479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03b_fraud_20220707104636\n",
      "projects/1026793852137/locations/us-central1/endpoints/6922833071733473280\n"
     ]
    }
   ],
   "source": [
    "for e in aiplatform.Endpoint.list():\n",
    "    if e.display_name.startswith('03b'): endpoint = e\n",
    "print(endpoint.display_name)\n",
    "print(endpoint.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b40faf0d-7a8d-4eb6-a04c-00bbde40dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_options = {\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"}\n",
    "predictor = aiplatform.gapic.PredictionServiceClient(client_options = client_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b156f3b9-9a89-43de-a10d-1008ee0f2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api import httpbody_pb2\n",
    "instances = {\"instances\": [newob], \"signature_name\": \"predict\"}\n",
    "http_body = httpbody_pb2.HttpBody(data = json.dumps(instances).encode(\"utf-8\"), content_type = \"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9b1e293-e75a-4449-b5a4-220a346ea882",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictor.raw_predict(endpoint = endpoint.resource_name, http_body = http_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2152e7c7-57a3-46df-b762-2a43d3178de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'classes': ['0'],\n",
       "   'all_class_ids': [0, 1],\n",
       "   'logistic': [0.999906898],\n",
       "   'all_classes': ['1', '0'],\n",
       "   'probabilities': [9.31419345e-05, 0.999906898],\n",
       "   'logits': [9.28129292],\n",
       "   'class_ids': [1]}]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(pred.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef471864-8a88-43b7-b9af-3215ac460ef9",
   "metadata": {},
   "source": [
    "### Get Predictions: REST\n",
    "This model does not have the default signature name expected by Vertex AI endpoint of \"serving_default\".  To get arround this we prepare the json input to include the correct signature name and use the [raw predict method documented here](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/rawPredict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6b3a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"signature_name\": \"predict\", \"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e7b1b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"probabilities\": [9.31419345e-05, 0.999906898],\n",
      "            \"logits\": [9.28129292],\n",
      "            \"class_ids\": [1],\n",
      "            \"classes\": [\"0\"],\n",
      "            \"all_class_ids\": [0, 1],\n",
      "            \"logistic\": [0.999906898],\n",
      "            \"all_classes\": [\"1\", \"0\"]\n",
      "        }\n",
      "    ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:rawPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752beb8-b4e7-45c8-8d2b-b36caace61e3",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)\n",
    "This model does not have the default signature name expected by Vertex AI endpoint of \"serving_default\".  To get arround this we prepare the json input to include the correct signature name and use the [raw predict method documented here](https://cloud.google.com/sdk/gcloud/reference/ai/endpoints/raw-predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3af5488f-5884-4e7d-a3e5-e6671d469d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"signature_name\": \"predict\", \"instances\": [newob]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3523017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"logistic\": [0.999906898],\n",
      "            \"all_classes\": [\"1\", \"0\"],\n",
      "            \"probabilities\": [9.31419345e-05, 0.999906898],\n",
      "            \"logits\": [9.28129292],\n",
      "            \"class_ids\": [1],\n",
      "            \"classes\": [\"0\"],\n",
      "            \"all_class_ids\": [0, 1]\n",
      "        }\n",
      "    ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints raw-predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --request=@{DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24191d22-46dd-4145-bbb9-ec4a6784a40a",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dcb5ce-ad81-42f3-80fe-71678df9c439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
